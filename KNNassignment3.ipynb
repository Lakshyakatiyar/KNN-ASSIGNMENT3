{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c9d093-0c8d-4a7a-bc63-f2c551016c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier with K=3: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target labels\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier with a chosen value of K (e.g., K=3)\n",
    "k = 3\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Train the KNN classifier on the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of KNN classifier with K={k}: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce6fff77-d79b-45dc-9922-4bdbaddda3df",
   "metadata": {},
   "source": [
    "3= for boston dataset it is showing some error that it has been removed from sns dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539b8e61-ac78-4a0a-973a-1922d925ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal K: 3\n",
      "Cross-Validated Accuracy with Optimal K: 0.96\n"
     ]
    }
   ],
   "source": [
    "#4=\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target labels\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a range of K values to test\n",
    "k_values = np.arange(1, 21)  # You can adjust the range as needed\n",
    "\n",
    "# Initialize variables to store cross-validation results\n",
    "best_k = None\n",
    "best_mean_accuracy = 0\n",
    "\n",
    "# Perform cross-validation for each K value and find the best K\n",
    "for k in k_values:\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn_classifier, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "    mean_accuracy = np.mean(scores)\n",
    "    \n",
    "    # Update the best K if the mean accuracy is higher\n",
    "    if mean_accuracy > best_mean_accuracy:\n",
    "        best_mean_accuracy = mean_accuracy\n",
    "        best_k = k\n",
    "\n",
    "# Print the best K value and its cross-validated accuracy\n",
    "print(f\"Optimal K: {best_k}\")\n",
    "print(f\"Cross-Validated Accuracy with Optimal K: {best_mean_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98ec12ec-ecc0-4547-b7ef-f62a406ebf2f",
   "metadata": {},
   "source": [
    "boston dataset from sns load dataset is not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb45676-2322-4a78-9a86-987515a7644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier with weighted voting: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target labels\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier with weighted voting (weights='distance')\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "\n",
    "# Train the KNN classifier on the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of KNN classifier with weighted voting: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28c46db9-1cde-4cf3-96b1-e6f2a36788d6",
   "metadata": {},
   "source": [
    "To standardize the features before applying a K-Nearest Neighbors (KNN) classifier, you can use the StandardScaler from scikit-learn. This ensures that all features have zero mean and unit variance, which is important for distance-based algorithms like KNN. Here's a Python function to do this:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardize the features using StandardScaler.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (numpy.ndarray): Training features.\n",
    "        X_test (numpy.ndarray): Test features.\n",
    "        \n",
    "    Returns:\n",
    "        X_train_std (numpy.ndarray): Standardized training features.\n",
    "        X_test_std (numpy.ndarray): Standardized test features.\n",
    "    \"\"\"\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the training data and transform both training and test data\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_std, X_test_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202ee618-67eb-463c-be48-18cba214834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean distance between (1, 2) and (4, 6) is 5.00\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points in a 2-dimensional space.\n",
    "    \n",
    "    Parameters:\n",
    "        point1 (tuple): Coordinates of the first point (x1, y1).\n",
    "        point2 (tuple): Coordinates of the second point (x2, y2).\n",
    "        \n",
    "    Returns:\n",
    "        float: Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    \n",
    "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    \n",
    "    return distance\n",
    "point1 = (1, 2)\n",
    "point2 = (4, 6)\n",
    "\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(f\"The Euclidean distance between {point1} and {point2} is {distance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf5ca02-ac2e-4019-9dcd-a074075ed817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance between (3, 5) and (1, 2) is 5\n"
     ]
    }
   ],
   "source": [
    "def manhattan_distance(x1, y1, x2, y2):\n",
    "    return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "# Example usage:\n",
    "point1 = (3, 5)\n",
    "point2 = (1, 2)\n",
    "distance = manhattan_distance(point1[0], point1[1], point2[0], point2[1])\n",
    "print(f\"Manhattan distance between {point1} and {point2} is {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362b3b4-4f19-4b5f-9ab6-7a660fcb5f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
